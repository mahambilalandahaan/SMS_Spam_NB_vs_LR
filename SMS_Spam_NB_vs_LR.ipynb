{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### üìå Executive Summary\n",
        "This project compares **Naive Bayes** and **Logistic Regression** models for SMS spam detection using both **CountVectorizer** and **TF-IDF** features.  \n",
        "Results show that while Naive Bayes is faster and simpler, **Logistic Regression with TF-IDF** achieves the **best balance of accuracy, recall, and overall performance**.\n",
        "---\n"
      ],
      "metadata": {
        "id": "4A2MGB50G2EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import e\n",
        "# LOAD DATASET USING URL\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "URL=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "urlretrieve(URL,\"smsspamcollection.zip\")\n",
        "zip_ref=zipfile.ZipFile(\"smsspamcollection.zip\",\"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "os.remove(\"smsspamcollection.zip\")\n",
        "\n",
        "#LOAD INTO DATAFRAME\n",
        "txt=pd.read_csv(\"SMSSpamCollection\",sep=\"\\t\",header=None,names=[\"label\",\"message\"])\n",
        "txt.head()\n",
        "txt.info()\n",
        "txt.keys()\n",
        "\n",
        "#MAP LABELS TO INTEGERS\n",
        "txt[\"label\"]=txt[\"label\"].map({\"ham\":0,\"spam\":1})\n",
        "\n",
        "#STANDARDIZING TEXT\n",
        "import string\n",
        "txt['message']=txt['message'].str.lower().str.replace(r'[^\\w\\s]',\" \", regex=True)\n",
        "\n",
        "#TRAIN/TEST SPLIT\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(txt[\"message\"],txt[\"label\"],test_size=0.2,random_state=42)\n",
        "\n",
        "#VECTORIZATION\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "counts=CountVectorizer(stop_words='english',max_features=2000 , ngram_range=(1,2))\n",
        "tfidf=TfidfVectorizer(stop_words='english',max_features=2000 , ngram_range=(1,2))\n",
        "x_train_counts=counts.fit_transform(X_train)\n",
        "x_train_tfidf=tfidf.fit_transform(X_train)\n",
        "X_test_counts=counts.transform(X_test)\n",
        "X_test_tfidf=tfidf.transform(X_test)\n",
        "\n",
        "#TRAIN MODELS\n",
        "#1)NAIVE BAYES MODEL\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb=MultinomialNB()\n",
        "nb_tfidf=nb.fit(x_train_tfidf,y_train)\n",
        "nb_counts=nb.fit(x_train_counts,y_train)\n",
        "#2)LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression( max_iter=2000, solver ='saga',penalty='l2',C=1.0,random_state=42 )\n",
        "lr_counts=lr.fit(x_train_counts,y_train)\n",
        "lr_tfidf=lr.fit(x_train_tfidf,y_train)\n",
        "\n",
        "#PREDICTIONS AND PROBABILITIES\n",
        "y_pred_nb_counts=nb_counts.predict(X_test_counts)\n",
        "y_pred_nb_tfidf=nb_tfidf.predict(X_test_tfidf)\n",
        "y_pred_lr_counts=lr_counts.predict(X_test_counts)\n",
        "y_pred_lr_tfidf=lr_tfidf.predict(X_test_tfidf)\n",
        "y_pob_nb_counts=nb_counts.predict_proba(X_test_counts)\n",
        "y_pob_nb_tfidf=nb_tfidf.predict_proba(X_test_tfidf)\n",
        "y_pob_lr_counts=lr_counts.predict_proba(X_test_counts)\n",
        "y_pob_lr_tfidf=lr_tfidf.predict_proba(X_test_tfidf)\n",
        "\n",
        "#EVALUATION\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_score,recall_score,roc_auc_score\n",
        "def evaluation(y_test,y_pred,y_pob):\n",
        "    return [round(accuracy_score(y_test,y_pred),4),\n",
        "          round(precision_score(y_test,y_pred),4),\n",
        "          round(recall_score(y_test,y_pred),4),\n",
        "          round(f1_score(y_test,y_pred),4),\n",
        "          round(roc_auc_score(y_test,y_pob[:,1]),4)\n",
        "          ]\n",
        "\n",
        "\n",
        "results={\n",
        "    \"NB Counts\":evaluation(y_test,y_pred_nb_counts,y_pob_nb_counts),\n",
        "    \"NB TFIDF\":evaluation(y_test,y_pred_nb_tfidf,y_pob_nb_tfidf),\n",
        "    \"LR Counts\":evaluation(y_test,y_pred_lr_counts,y_pob_lr_counts),\n",
        "    \"LR TFIDF\":evaluation(y_test,y_pred_lr_tfidf,y_pob_lr_tfidf)\n",
        "}\n",
        "\n",
        "df_results=pd.DataFrame(results).T\n",
        "df_results.columns=[\"Accuracy Score\",\"Precision Score\",\"Recall Score\",\"F1 Score\",\"ROC AUC Score\"]\n",
        "display(df_results.head())\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(name,y_test,y_pred):\n",
        "  print(f\"Confusion matrix of {name} :\")\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Ham\",\"Spam\"], yticklabels=[\"Ham\",\"Spam\"])\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.title(f\"Confusion Matrix for {name}\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_confusion_matrix(\"NB Counts\",y_test,y_pred_nb_counts)\n",
        "plot_confusion_matrix(\"NB TFIDF\",y_test,y_pred_nb_tfidf)\n",
        "plot_confusion_matrix(\"LR Counts\",y_test,y_pred_lr_counts)\n",
        "plot_confusion_matrix(\"LR TFIDF\",y_test,y_pred_lr_tfidf)"
      ],
      "metadata": {
        "id": "EU8ua9iPOFFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### üìå Bottom Line\n",
        "\n",
        "- **Naive Bayes (NB)**  \n",
        "  ‚úÖ Very fast, lightweight, and easy to implement.  \n",
        "  ‚úÖ Performs surprisingly well on text data.  \n",
        "  ‚ùå Assumes independence between words (bag-of-words), which is not always true.  \n",
        "  ‚ùå Slightly lower recall compared to Logistic Regression (misses some spam).  \n",
        "\n",
        "- **Logistic Regression (LR)**  \n",
        "  ‚úÖ More powerful and flexible than NB.  \n",
        "  ‚úÖ Generally achieves higher accuracy, recall, and F1-score.  \n",
        "  ‚úÖ Handles overlapping word distributions better.  \n",
        "  ‚ùå Slower to train compared to NB.  \n",
        "  ‚ùå Requires parameter tuning (e.g., regularization, solver).  \n",
        "\n",
        "- **Feature Comparison**  \n",
        "  - **CountVectorizer**: Simple word frequency counts, fast, but less informative.  \n",
        "  - **TF-IDF**: Weighs words by importance, reduces impact of common words ‚Üí **consistently better performance**.  \n",
        "\n",
        "üìä **Best performer in this study:**  \n",
        "**Logistic Regression with TF-IDF** ‚Üí balanced precision, recall, and overall accuracy, making it the most reliable for spam detection in this dataset.\n",
        "---\n"
      ],
      "metadata": {
        "id": "QPYgEsWTGtaO"
      }
    }
  ]
}